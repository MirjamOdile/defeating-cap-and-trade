{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the witnesses giving testimony\n",
    "\n",
    "#### This script extracts the information about the hearings as well as the witnesses giving testimony - where available, from the metadata files otherwise manually from the  transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CommitteeHearingsFunctions import *\n",
    "\n",
    "# Change directory\n",
    "os.chdir('../../Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "with open('CommitteeHearings/hearings.json', 'r') as file:\n",
    "    df = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract hearings information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract chamber and committee\n",
    "for text in df:\n",
    "    # Extract the witnesses\n",
    "    text['chamber'] = first_match(['<chamber>(.+?)</chamber>'], str(text['mods']))\n",
    "    text['committee'] = first_match(['<name type=\"authority-standard\">(.+?)</name>'], str(text['mods']))\n",
    "    text['committee_short'] = first_match(['<name type=\"authority-short\">(.+?)</name>'], str(text['mods']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add witnesses from the metadata files (mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Witnesses were found for 83 of the 117 hearing.\n"
     ]
    }
   ],
   "source": [
    "count_MODS = 0\n",
    "for text in df:\n",
    "    text['witnesses_mods'] = []\n",
    "    # Extract the witnesses\n",
    "    text['witnesses_mods'] = all_matches(['<witness>(.+?)</witness>'], str(text['mods']))\n",
    "    # Replace wrongly parsed information\n",
    "    for i, witness in enumerate(text['witnesses_mods']):\n",
    "        text['witnesses_mods'][i] = re.sub(\"Answers(.+?)\\\\\\\\\\d\\\\\\\\[\\.]{0,}\\s?\", \"\", text['witnesses_mods'][i])\n",
    "        text['witnesses_mods'][i] = re.sub(\"\\s?\\\\\\\\\\d\\\\\\\\(.+?)Prepared statement\", \"\", text['witnesses_mods'][i])\n",
    "        text['witnesses_mods'][i] = re.sub(\", prepared statement\", \"\", text['witnesses_mods'][i])\n",
    "        text['witnesses_mods'][i] = re.sub(\"\\s?\\\\\\\\\\d\\\\\\\\(.+?)submitted questions\", \"\", text['witnesses_mods'][i])\n",
    "        text['witnesses_mods'][i] = re.sub(\"; Accompanied by(.+)$\", \"\", text['witnesses_mods'][i])\n",
    "        text['witnesses_mods'][i] = re.sub(\"National Resources Defense Council\", \"Natural Resources Defense Council\", text['witnesses_mods'][i])\n",
    "    # Count hearings with successfully extracted witness information\n",
    "    if len(text['witnesses_mods']) > 0:\n",
    "        count_MODS += 1\n",
    "print('Witnesses were found for {} of the {} hearing.'.format(count_MODS, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process the witness information from the mods\n",
    "for i, text in enumerate(df):\n",
    "    # Drop non-witness entries wrongly included as witnesses in the mods file\n",
    "    df[i]['witnesses_mods'] = [w for w in df[i]['witnesses_mods'] if not\n",
    "                               w.lower().startswith(('analysis', 'article', 'clean', 'excerpt', 'letter', \n",
    "                                                     'newspaper', 'polar bear', 'position paper', \n",
    "                                                     'prepared statement', 'report', 'supplement to'))]\n",
    "    if text['identifier'] =='108shrg91748':   \n",
    "    # Drop opening statements wrongly included as witnesses in the mods file\n",
    "        df[i]['witnesses_mods'] = [w for w in df[i]['witnesses_mods'] if \n",
    "                               len(re.findall('senator', w.lower())) == 0]\n",
    "# Note: There are still several Senators in the mods witnesses. However, manual checking revealed that all of these\n",
    "# were not committee members giving opening statements but rather invited to testify as witnesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Print witnesses extracted from mods and the urls to the respective htm and mods\n",
    "# for i, text in enumerate(df):\n",
    "#     if text['witnesses_mods'] != []:\n",
    "#         print(i, text['identifier'])\n",
    "#         for witness in text['witnesses_mods']:\n",
    "#             print(witness)\n",
    "#         get_htm(text['identifier'])\n",
    "#         get_mods(text['identifier'])\n",
    "#         print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually add witnesses for hearings with missing witness metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions for witness extraction (need to be run in order)\n",
    "regex1 = ['STATEMENTS\\n+\\s*Page\\n+(.+?)\\n+\\s*(?:APPENDIX|CLIMATE CHANGE)']\n",
    "regex2 = ['Testimony of:\\n+\\s*(.+?)\\n+\\s*Addit[i]?onal material submitted for the record:']\n",
    "regex3 = ['TESTIMONY\\n+\\s*(.+?)\\n+\\s*PREPARED']\n",
    "regex4 = ['Witnesses:?\\n+\\s*(.+?)\\n\\nDiscussion', 'Panel I+:\\n+\\s*(.+?)Discussion']\n",
    "regex5 = ['Witnesses:?\\n+\\s*(.+?)\\n\\n']\n",
    "regex6 = ['Statement of:\\n+\\s*(.+?)\\n+\\s*(?:Letters|COUNTING)']\n",
    "regex7 = ['STATEMENTS\\n+\\s*\\w+\\s\\d{2},\\s\\d{4}\\n+(.+?)\\n+\\s*(?:\\w+\\s\\d{2},\\s\\d{4})(.+?)\\n+\\s*APPENDIX']\n",
    "regex8 = ['Page\\s+(.+?)\\s+(?:Additional Statement|SUBMISSIONS|Additional Material|\\(iii\\)|POLICY OPTIONS)']\n",
    "regex9 = ['Statement of (?!Sen)(.+?)\\.+\\s*\\d+\\n+']\n",
    "regex10 = ['Witness:\\s+(.+?)Oral Statement']\n",
    "regex11 = ['Panel I+\\n+\\s*(.+?)\\n{2,}']\n",
    "# regex12 = ['STATEMENT[S]* OF\\s*(\\\\b[^a-z]+[a-z]?[^a-z]+\\\\b)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Witnesses were found for 34 of the 34 hearings missing witness information.\n"
     ]
    }
   ],
   "source": [
    "# Match the witnesses consecutively with the regular expressions defined above\n",
    "count = 0\n",
    "for i, text in enumerate(df):\n",
    "    text['witnesses_htm'] = []\n",
    "    if len(text['witnesses_mods']) == 0:\n",
    "# Match the witnesses\n",
    "        text['witnesses_htm'] = all_matches(regex1, str(text['htm']))\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex2, str(text['htm']))\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex3, str(text['htm'][0:20000]))\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex4, str(text['htm']))\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex5, str(text['htm']))    \n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex6, str(text['htm']))\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = [''.join(item) for item in all_matches(regex7, str(text['htm']))]\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex8, str(text['htm']))\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex9, str(text['htm']))\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex10, str(text['htm']))\n",
    "        if len(text['witnesses_htm']) == 0:\n",
    "            text['witnesses_htm'] = all_matches(regex11, str(text['htm']))\n",
    "        if len(text['witnesses_htm']) > 0:\n",
    "                count += 1\n",
    "#                 Uncomment below to print the matches\n",
    "#                 print(i, text['identifier'], '\\n', text['witnesses_htm'])\n",
    "#                 get_htm(text['identifier'])\n",
    "#                 print('\\n\\n')\n",
    "        else:\n",
    "            print(i)\n",
    "print('Witnesses were found for {} of the {} hearings missing witness information.'.format(count, len(df) - count_MODS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Post-process the witness information from the transcripts\n",
    "for i, text in enumerate(df):\n",
    "    text['witnesses'] = []\n",
    "    if text['witnesses_htm'] != []:\n",
    "        for j, witnesses in enumerate(text['witnesses_htm']):\n",
    "            # Split the multi-witness blocks into individual witnesses\n",
    "            text['witnesses'].append(re.split(r'\\.*\\s{3,}\\d+\\n*|\\.{5,}\\n|;\\s+(?:and )?', \n",
    "                                              text['witnesses_htm'][j]))\n",
    "        # Flatten the list\n",
    "        text['witnesses'] = [item for sublist in text['witnesses'] for item in sublist]\n",
    "        for k, witness in enumerate(text['witnesses']):\n",
    "            witness_clean = re.sub('[\\n\\s]+', ' ', witness.strip())\n",
    "            df[i]['witnesses'][k] = witness_clean\n",
    "        # Drop empty entries\n",
    "        text['witnesses'] = [w for w in text['witnesses'] if not w == '']\n",
    "        # Drop non-witness entries\n",
    "        text['witnesses'] = [w for w in text['witnesses'] if not\n",
    "                             w.startswith(('accompanied by', 'Article', 'Biography', 'Prepared',\n",
    "                                           'Paper', 'Responses', 'Written', '---'))]\n",
    "        # Drop opening statements\n",
    "        text['witnesses'] = [w for w in text['witnesses'] if not\n",
    "                             all_matches(['chairman, house', 'representative in congress',\n",
    "                                          'ranking \\w*\\s*member', 'senator'], w.lower())]\n",
    "        # Drop exact duplicates\n",
    "        text['witnesses'] = [w for w in set(text['witnesses'])]\n",
    "        # Drop partial duplicates () for hearing '109hhrg29932'\n",
    "        if text['identifier'] == '109hhrg29932':\n",
    "             text['witnesses'] = [w for w in text['witnesses'] if len(w.split())>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print witnesses extracted from the htm and the urls to the respective htm and mods\n",
    "# for i, text in enumerate(df):\n",
    "#     if text['witnesses'] != []:\n",
    "#         print(i, text['identifier'])\n",
    "#         for witness in text['witnesses']:\n",
    "#             print(witness)\n",
    "#         get_htm(text['identifier'])\n",
    "#         get_mods(text['identifier'])\n",
    "#         print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the witness information from both sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Witnesses for 117 out of 117 hearings have been matched.\n"
     ]
    }
   ],
   "source": [
    "# Join the witness information\n",
    "matched = 0\n",
    "for i, text in enumerate(df):\n",
    "    if text['witnesses'] == []:\n",
    "        text['witnesses'] = text['witnesses_mods']\n",
    "    if text['witnesses'] != []:\n",
    "        matched += 1\n",
    "print('Witnesses for {} out of {} hearings have been matched.'.format(matched, len(df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmstead, Hon. Jeffrey, Assistant Administrator for Air and Radiation, Environmental Protection Agency\n",
      "Thorning, Margo, Ph.D., senior vice president and chief economist, American Council for Capital Formation\n",
      "Lisa Jacobson, Executive Director, Business Council for Sustainable Energy\n",
      "Doniger, David, Policy Director, Climate Center, Natural Resources Defense Council\n"
     ]
    }
   ],
   "source": [
    "# Correct misspellings\n",
    "for i, text in enumerate(df):\n",
    "    for j, w in enumerate(text['witnesses']):\n",
    "        if re.findall('Holmstead, Hon. Jeffery', w):\n",
    "            print(w.replace('Jeffery', 'Jeffrey'))\n",
    "            df[i]['witnesses'][j] = w.replace('Jeffery', 'Jeffrey')\n",
    "        if re.findall('(American|Business|Defense) Counsel', w):\n",
    "            print(w.replace('Counsel', 'Council'))\n",
    "            df[i]['witnesses'][j] = w.replace('Counsel', 'Council')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brownstein, Mark S., director, Enterprise Strategy\n",
      ">> Brownstein, Mark S., director, Enterprise Strategy, PSEG Service Corporation \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add missing witness information\n",
    "print(df[3]['witnesses'][13])\n",
    "df[3]['witnesses'][13] = 'Brownstein, Mark S., director, Enterprise Strategy, PSEG Service Corporation'\n",
    "print('>>', df[3]['witnesses'][13], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the temporary witness variables 'witnesses_mods' & witnesses_htm\n",
    "df = drop_variables(df, ['witnesses_mods', 'witnesses_htm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "with open('CommitteeHearings/hearings_witnesses.json', 'w') as file:\n",
    "    json.dump(df, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cards-github",
   "language": "python",
   "name": "cards-github"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
